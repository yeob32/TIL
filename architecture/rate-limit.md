# Rate Limit

- 특정 임계치까지만 클라이언트의 요청을 허용하는 정책
- 과도한 트래픽으로부터 서비스의 안정성을 보장해준다. 가용성 확보
- 외부 사용자의 요청이라면 API Gateway 또는 LB 에서 → Rate Limit 체크 후 Application
- 보통 유저별(UserId,API Key, IP Address)로 많이 건다.
- HTTP Header
    - X-Ratelimit-Remaining: 윈도 내 남은 처리가능 요청 수
    - X-Ratelimit-Limit: 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수
    - X-Ratelimit-Retry-After: 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 보내야하는 지 알림
- 처리율 한도 초과 트래픽의 처리
    - 응답 시 429 Too Many Request
    - 메세지를 별도의 큐에 보관 후 나중에 처리
- 분산환경
    - 동시에 카운터 업데이트 시 race condition 발생 가능
    - DB 또는 Redis Lock → 성능 이슈
        - lua script, 정렬 집합 레디스 자료구조
- rate limit 서버가 여러대면 동기화 신경 써야함 → redis 같은 중앙 집중형 데이터 저장소 사용
- 모니터링
    - rate limit 처리량이 효과적인지

### Rate Limit 알고리즘

- Memory Estimation
    - 해시테이블을 사용한다고 가정할 때
    - IP: 16byte
    - count: 2byte (~6만5천)
    - startTime: 2byte (분,초단위 값)
    - Lock: 4byte - 레코드 수정할 때마다 mutext 사용할 때
    - 해시테이블이 각 레코드마다 추가 20byte 필요하다고 했을 때 100만명 유저 관리 시 (24 + 20)byte + 1,000,000 = 44MB
- **Leaky Bucket**
    - 요청 처리율이 고정되어 있음
    - 보통 FIFO Queue 같은 걸로 일정한 처리속도와 처리할 수 있는 양을 제어
    - 일정 주기로 처리, Queue 가 가득차 있을 때는 요청 거절, 아니라면 허용
    - 장점
        - 일정한 속도로 요청 처리 가능, 구현이 간단함, 큐 사이즈 정해져있어서 메모리 효율 좋음
    - 단점
        - 요청의 양에 비해 처리속도가 늦을 경우, 새로운 요청은 거의 처리 불가
- **Token Bucket**
    - 토큰 버킷 → 지정된 용량을 갖는 컨테이너
    - 토큰 공급기에 의해 사전 설정된 양의 토큰이 주기적으로 채워짐. 버킷이 가득차면 추가로 공급된 토큰은 버려진다.
    - fixed window 처럼 특정 기간 단위로 추가하는게 아니라 일정 속도에 맞춰서 추가해줘야함 (1분에 10개면 6초당 1개씩 추가)
      즉, token bucket 에 token 을 요청에 맞는 일정 속도로 추가함, 토큰 고갈되면 요청 처리 불가
    - 장점
        - Max concurrency 관리에 용이
        - burst of request 도 일정수준은 유연하게 처리 가능
    - 단점
        - 분산환경에서 race condition 발생 가능
- **Fixed Window**
    - 타임라인을 고정된 간격의 윈도로 나누고, 윈도마다 카운터를 붙임
    - 요청마다 카운터 1증가, 카운터의 값이 임계치에 도달 시 새로운 요청은 새 윈도가 열릴 때 까지 버려짐
    - 새 윈도가 열리면 카운터 초기화
    - 장점
        - 메모리 효율
        - 윈도가 열릴 때 카운터가 초기화되는 방식은 특정 트래픽 패턴을 처리하기 적합함
    - 단점
        - 경계부분에 요청이 몰리면, 제한하고 싶은 한도보다 많은 요청을 처리할 수 있음
- **Sliding Window Log**
    - Fixed Window 알고리즘 문제를 해결하기 위해 고안
    - 요청의 타임스탬프를 추적. 타임스탬프 로그를 레디스 또는 정렬 집합 같은 캐시에 저장
    - 새 요청이 왔을 때, 캐시에 저장된 타임스탬프 중 만료된 타임스탬프는 제거
    - 새 요청의 타임스탬프를 로그(캐시)에 추가
    - 로그의 양이 허용치보다 같거나 작으면 요청 수행
    - 장점
        - 처리율 제한 매커니즘이 아주 정교함 → 어느 순간의 윈도를 보더라도 허용되는 요청의 개수는 시스템 처리율 한도를 넘지 않을 것
    - 단점
        - 다량의 메모리가 필요. 거부된 요청의 타임스탬프도 보관함
- **Sliding Window Counter**
    - Fixed Window 와 Sliding Window Log 알고리즘 결합
    - 현재 윈도우와 현재 시간을 보고, 들어온 요청의 비율을 따져서 처리할지 판단
        - ex) 윈도우 크기 1분
            - 현재 1분간의 요청 수 + 직전 1분간의 요청 수 * 이동 윈도(현재 요청으로부터 1분 간)와 직전 1분이 겹치는 비율
        - 다양한 알고리즘 있음
    - 장점
        - 이전 윈도의 평균 처리율과 현재 윈도 상태를 측정해 계산하므로 짧은 시간에 몰리는 트래픽에도 잘 대응
    - 단점
        - 직전 윈도(시간)에 도착한 요청이 균등하게 분포되어있다고 가정하고 위와 같은 식을 사용. 이것도 경계 부분에 몰렸을 경우, 계산이 예상한 결과와 다르게 동작할 수 있음. 근데 클라우드플레어에서 수행한 실험에 의하면 이런 경우는 0.003%에 불과했다고 함.
    - Counter 는 레디스에 저장
        - 빠르고, 시간에 기반한 만료 정책 지원
        - INCR, EXPIRE 명령어 지원

### 구현

- 간단하게는 redis 의 key 와 expire 를 이용해서 뭐 몇초동안의 count 와 limit 를 비교해서 처리
- redis transaction watch, unwatch
- Lua script
    - Lua script를 작성하고 Lua script을 실행시켜서 atomic연산이 보장되도록 개선
    - Redis에서 Lua Script를 실행시킬 경우 해당 스크립트는 반드시 짧게 끝나는 로직으로 작성
        - 처리시간이 오래 걸리는 로직이 들어가면 싱글스레드 기반의 레디스는 해당 스크립트를 실행하는 동안 다른 요청을 처리하지 못하는 일이 발생합니다.

### resilience4j Rate Limit

- 일정 시간동안 target application/method 호출 요청 횟수를 제한하는 기능
- 옵션
    - limit-for-period : 한번에 처리 가능한 요청 개수
    - limit-refresh-period : 다음 `limit-for-period` 횟수 만큼 처리 하기 위해서 기다려야 하는 대기 시간
    - timeout-duration : 대기 시간의 timeout 시간 설정